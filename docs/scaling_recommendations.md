# üéØ –ê–Ω–∞–ª–∏–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ EuroAutoDataHub

## üìä –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
- ‚úÖ –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Kafka –¥–ª—è async –æ–±—Ä–∞–±–æ—Ç–∫–∏
- ‚úÖ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è
- ‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
- ‚úÖ PostgreSQL –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

**–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:**
- üî¥ **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ:** –ë–ª–æ–∫–∏—Ä—É—é—â–∏–π Scrapy, –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π Kafka broker, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
- üü° **–í–∞–∂–Ω—ã–µ:** –ù–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞, –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç rate limiting, –Ω–µ—Ç graceful shutdown
- üü¢ **–ñ–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ:** –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ CI/CD, –Ω–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

---

## üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ø—Ä–æ–±–ª–µ–º—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è

### 1. **–ë–ª–æ–∫–∏—Ä—É—é—â–∏–π Scrapy Spider**
**–¢–µ–∫—É—â–∞—è –ø—Ä–æ–±–ª–µ–º–∞:** Spider –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
```python
# otomoto.py - —Ç–µ–∫—É—â–∏–π –∫–æ–¥
def parse_page(self, response, meta=None):
    # –ë–ª–æ–∫–∏—Ä—É—é—â–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    for edge in edges:
        # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
```

**–†–µ—à–µ–Ω–∏–µ - —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞:**
```python
# settings.py - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
CONCURRENT_REQUESTS = 32  # –£–≤–µ–ª–∏—á–∏—Ç—å —Å 10 –¥–æ 32
CONCURRENT_REQUESTS_PER_DOMAIN = 8  # –î–æ–±–∞–≤–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –¥–æ–º–µ–Ω
DOWNLOAD_DELAY = 0.1  # –£–º–µ–Ω—å—à–∏—Ç—å –∑–∞–¥–µ—Ä–∂–∫—É —Å 0.5
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 0.1
AUTOTHROTTLE_MAX_DELAY = 3
AUTOTHROTTLE_TARGET_CONCURRENCY = 16
AUTOTHROTTLE_DEBUG = True  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
```

**–†–µ—à–µ–Ω–∏–µ - batch –æ–±—Ä–∞–±–æ—Ç–∫–∞:**
```python
class OptimizedOtomotoSpider(scrapy.Spider):
    def __init__(self):
        self.batch_size = 100
        self.current_batch = []
    
    def parse_page(self, response):
        """Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–º–µ—Å—Ç–æ –ø–æ—à—Ç—É—á–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏"""
        edges = self.extract_edges(response)
        
        for edge in edges:
            item = self.create_item(edge)
            self.current_batch.append(item)
            
            if len(self.current_batch) >= self.batch_size:
                yield from self.send_batch()
    
    def send_batch(self):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ–º batch –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        for item in self.current_batch:
            yield item
        self.current_batch = []
```

### 2. **–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π Kafka broker**
**–ü—Ä–æ–±–ª–µ–º–∞:** –û–¥–Ω–∞ —Ç–æ—á–∫–∞ –æ—Ç–∫–∞–∑–∞, –Ω–µ—Ç —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏
```yaml
# docker-compose.yml - —Ç–µ–∫—É—â–∏–π –∫–æ–¥
kafka_broker:
  image: confluentinc/cp-kafka:7.3.2
  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –±—Ä–æ–∫–µ—Ä!
```

**–†–µ—à–µ–Ω–∏–µ - Kafka –∫–ª–∞—Å—Ç–µ—Ä:**
```yaml
# docker-compose.kafka-cluster.yml
services:
  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      
  kafka2:
    image: confluentinc/cp-kafka:7.3.2
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
      
  kafka3:
    image: confluentinc/cp-kafka:7.3.2
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094
```

### 3. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è**
**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∫ –ë–î, –Ω–µ—Ç –∫—ç—à–∞ –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

**–†–µ—à–µ–Ω–∏–µ - Redis –∫—ç—à:**
```yaml
# docker-compose.yml - –¥–æ–±–∞–≤–∏—Ç—å Redis
services:
  redis:
    image: redis:7-alpine
    container_name: redis_cache
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
```

```python
# api_service - –¥–æ–±–∞–≤–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
import redis
from functools import wraps

redis_client = redis.Redis(host='redis', port=6379, decode_responses=True)

def cache_result(expiry=300):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏ –∫—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = await func(*args, **kwargs)
            redis_client.setex(cache_key, expiry, json.dumps(result, default=str))
            return result
        return wrapper
    return decorator

@cache_result(expiry=600)  # 10 –º–∏–Ω—É—Ç
async def get_popular_makes():
    # –ö—ç—à–∏—Ä—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–∞—Ä–∫–∏
    pass
```

---

## üü° –í–ê–ñ–ù–´–ï –ø—Ä–æ–±–ª–µ–º—ã

### 4. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –º–µ—Ç—Ä–∏–∫**
**–†–µ—à–µ–Ω–∏–µ - –¥–æ–±–∞–≤–∏—Ç—å Prometheus + Grafana:**
```yaml
# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
```

```python
# –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ Scrapy
from prometheus_client import Counter, Histogram, start_http_server

SCRAPED_ITEMS = Counter('scraped_items_total', 'Total scraped items', ['spider', 'source'])
RESPONSE_TIME = Histogram('response_time_seconds', 'Response time', ['spider'])

class MetricsSpider(scrapy.Spider):
    def parse(self, response):
        with RESPONSE_TIME.labels(spider=self.name).time():
            # –ü–∞—Ä—Å–∏–Ω–≥
            items = self.extract_items(response)
            SCRAPED_ITEMS.labels(spider=self.name, source=self.source).inc(len(items))
```

### 5. **–ù–µ—Ç graceful shutdown**
```python
# consumer.py - –¥–æ–±–∞–≤–∏—Ç—å graceful shutdown
import signal
import sys

class GracefulKafkaConsumer:
    def __init__(self):
        self.running = True
        signal.signal(signal.SIGINT, self.stop)
        signal.signal(signal.SIGTERM, self.stop)
    
    def stop(self, signum, frame):
        self.logger.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, –∑–∞–≤–µ—Ä—à–∞–µ–º gracefully...")
        self.running = False
    
    async def consume(self):
        while self.running:
            try:
                message = await self.consumer.getone()
                await self.process_message(message)
            except Exception as e:
                if self.running:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
```

### 6. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ rate limiting**
```python
# api_service - –¥–æ–±–∞–≤–∏—Ç—å rate limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.get("/api/v1/ads")
@limiter.limit("100/minute")  # 100 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É
async def get_ads(request: Request):
    pass
```

---

## üü¢ –ñ–ï–õ–ê–¢–ï–õ–¨–ù–´–ï —É–ª—É—á—à–µ–Ω–∏—è

### 7. **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π Scrapy**
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Scrapy-Redis –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
# requirements.txt
scrapy-redis==0.7.3

# settings.py
SCHEDULER = "scrapy_redis.scheduler.Scheduler"
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"
SCHEDULER_PERSIST = True
SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.SpiderPriorityQueue'

REDIS_HOST = 'redis'
REDIS_PORT = 6379
```

### 8. **Database partitioning**
```sql
-- –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã auto_ad –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É –∏ –¥–∞—Ç–µ
CREATE TABLE auto_ad_otomoto_2025_01 PARTITION OF auto_ad
FOR VALUES FROM ('otomoto.pl', '2025-01-01') TO ('otomoto.pl', '2025-02-01');

-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX CONCURRENTLY idx_auto_ad_make_model_year 
ON auto_ad (make_name, model_name, year) 
WHERE sold_at IS NULL;
```

### 9. **CI/CD Pipeline**
```yaml
# .github/workflows/deploy.yml
name: Deploy EuroAutoDataHub
on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run tests
        run: |
          docker-compose -f docker-compose.test.yml up --abort-on-container-exit
          
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production
        run: |
          docker-compose -f docker-compose.prod.yml up -d --no-deps --build
```

---

## üìà –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –§–∞–∑–∞ 1 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è - 1-2 –Ω–µ–¥–µ–ª–∏)
1. ‚úÖ –£–≤–µ–ª–∏—á–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º Scrapy (CONCURRENT_REQUESTS = 32)
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å batch –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ pipeline
3. ‚úÖ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Kafka –∫–ª–∞—Å—Ç–µ—Ä (3 –±—Ä–æ–∫–µ—Ä–∞)
4. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

### –§–∞–∑–∞ 2 (–í–∞–∂–Ω–∞—è - 2-3 –Ω–µ–¥–µ–ª–∏)  
1. ‚úÖ –í–Ω–µ–¥—Ä–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (Prometheus + Grafana)
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å graceful shutdown
3. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å rate limiting –≤ API
4. ‚úÖ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–ª–µ—Ä—Ç—ã

### –§–∞–∑–∞ 3 (–ñ–µ–ª–∞—Ç–µ–ª—å–Ω–∞—è - 1-2 –º–µ—Å—è—Ü–∞)
1. ‚úÖ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π Scrapy —á–µ—Ä–µ–∑ Redis
2. ‚úÖ –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ë–î
3. ‚úÖ CI/CD –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è
4. ‚úÖ Load balancing –¥–ª—è API

---

## üöÄ –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤ 5-10 —Ä–∞–∑
- **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å:** 99.9% uptime
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å:** –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ 100+ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤
- **Monitoring:** –ü–æ–ª–Ω–∞—è –≤–∏–¥–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
